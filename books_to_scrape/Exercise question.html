<h4><strong>Books to scrape !</strong></h4><p>Hi there, </p><p>This time your job is to build a Crawler which will crawl all the books from all the available pages in this website '<a href="http://books.toscrape.com/" rel="noopener noreferrer" target="_blank">http://books.toscrape.com/</a>'</p><figure><img src="https://udemy-images.s3.amazonaws.com:443/redactor/raw/2019-09-18_12-38-50-370dd77e304a71e3a327927edd21ba45.PNG"></figure><p>This website was mainly created for scraping purpose by "<strong>ScrapingHub</strong>" the company behind Scrapy.</p><p>As mentioned previously the goal is to visit each book page and scrape the "<strong>book name</strong>" and the "<strong>price</strong>" from all the available pages.</p><figure><img src="https://udemy-images.s3.amazonaws.com:443/redactor/raw/2019-09-18_12-40-54-56102fdb7d3a05ec61ecbf89db0d56a4.PNG"></figure><p>Now, because this is the first time you build a <strong>CrawlSpider</strong>, I'm gonna give you a little of guidance:</p><ul><li><p>You probably need to write two "Rule" objects:</p><ul><li><p>The first Rule object will handle opening each book URL</p></li><li><p>The second Rule object will handle pagination</p></li></ul></li><li><p>Make sure to store all the data in a JSON&nbsp;or a CSV&nbsp;file it's up to you.</p></li></ul><p>Feel free to download the solution from this link "<a href="https://www.dropbox.com/sh/a8anjg5z1oinxhv/AABWn-1nH-gJ7FMc6aoTrLy0a?dl=0" rel="noopener noreferrer" target="_blank">https://www.dropbox.com/sh/a8anjg5z1oinxhv/AABWn-1nH-gJ7FMc6aoTrLy0a?dl=0</a>".</p><p>Good luck,</p><p>Ahmed</p>